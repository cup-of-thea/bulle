---
title: "Non je n'utiliserai pas l'IA"
description: "Dans cette première battle, Magali et Emmanuelle débattent de l'utilisation de l'IA, de ses problématiques éthiques... ici, Magali prend la position du non. "
date: 2024-09-30
authors: [ "Magali" ]
category: "Battle"
edition: "Septembre 2024"
tags: ["IA", "éthique", "tech"]
---

Ça fait un moment que je réfléchis à un article sur l'IA (Intelligence Artificielle) et que je cherche un angle et un format sous lesquels aborder ce thème, que j'ai déjà évoqué à plusieurs reprises en sous-thème dans mes conférences. J'ai finalement proposé d'en faire un article pour cette édition, et tout de suite, Emmanuelle a sauté sur l'occasion et a proposé de faire une battle. Ça faisait un moment qu'on discutait ensemble de ces questions, et qu'on n'était pas toujours d'accord, donc j'ai trouvé l'idée super intéressante ! Voici donc, ma partie, un article à charge (en essayant d'être juste) contre l'utilisation à outrance de l'IA.

*Note : La plupart du temps, à la place de IA, on devrait en fait dire LLM (Large Language Models). Ce qu'on utilise aujourd'hui n'est pas de l'IA à proprement parler, il n'y a pas d'intelligence, mais bien des modèles statistiques qui étudient le langage et permettent de créer des réponses grâce à des bases de données. Le terme IA est utilisé principalement pour une question de marketing, afin de donner l'impression que l'outil est beaucoup plus puissant qu'il ne l'est, d'ailleurs à chaque fois qu'on entend des entreprises qui poussent l'IA, elles ne parlent pas de ce que l'IA fait aujourd'hui, mais de ce que ça pourra faire un jour (et souvent sans réel appui technique).*

*Bref, ici on utilisera IA durant l'article parce que c'est ainsi que les gens nomment ces outils, mais je trouve dommage qu'on n'utilise pas le terme approprié, qui au moins évite d'avoir une vision déformée de ces outils.*

## 1. Bon en fait si...

Ça commence mal, je vous ai menti. Bien sûr que j'utilise l'IA. De toute façon, c'est quasiment impossible de ne pas l'utiliser aujourd'hui, à moins peut-être de vivre une vie de parfait·e luddite  [^1]. L'IA a été ajoutée à plein d'outils du quotidien pour les rendre plus efficaces : moteurs de recherche, outils de modifications d'images, outils d'enregistrement de voix (podcasts, etc), outils de réunions virtuelles (Zoom par exemple)... 

D'une manière général, il y a plein d'utilisations très pratiques de l'IA. De fait, avoir la possibilité de faire des transcripts grâce à l'IA est pour moi une vraie révolution. Un de mes boulots étudiants était de faire des transcripts d'interviews... à l'époque où ça se faisait manuellement. Je peux vous dire que le temps gagné est déjà un gros argument pro IA, même en sachant que les transcripts générés automatiquement sont loin d'être parfaits et qu'il reste un gros travail de nettoyage à faire. En attendant, ça réduit une tâche très ingrate à peut-être un dixième du temps qu'on lui consacrait avant ? [^2]

D'ailleurs d'une manière générale, l'IA est pas mal utile pour des questions d'accessibilité. D'ailleurs, on a récemment vu des entreprises justifier leur utilisation de l'IA pour générer des contenus par la question de l'accessibilité, de façon malhonnête [^3]. Mais en dehors de ces dérives, c'est un des meilleurs arguments pro-IA pour moi. Il y a bien sûr les transcripts dont je viens de parler (rappelons que si vous faites un podcast, ne pas faire de transcript exclue les personnes sourdes et malentendantes de votre public), mais aussi les sous-titres (et même s'ils sont limités et qu'en live c'est pas parfait, c'est quand même mieux que rien), le speech-to-text... Et il y a aussi des tas de projets, plus ou moins pertinents, utilisant l'IA, allant de la création d'alt-text automatisés (c'est loin d'être acquis encore) à des projets d'exosquelettes en passant par des IA permettant aux personnes aveugles de se diriger dans le monde.... Bref, s'il y a un domaine où je pense que l'IA pourrait être utile, et où je peux parfois m'enthousiasmer (pas pour les exosquelettes hein par contre), c'est bien l'accessibilité, numérique ou irl (in real life). 

Dans le même ordre d'idées, il y a des utilisations de l'IA dans la médecine et en théorie, ça semble plutôt intéressant. Des aides au diagnostic, des chirurgies assistées par l'IA, de l'aide à la prévention, des recommandations de traitements, voire la médecine prédictive... Il semblerait que l'utilisation de l'IA en médecine soit sans limite et pourrait complètement révolutionner ce domaine. En théorie, dans un monde où les déserts médicaux rendent quasi impossible le fait d'être réellement suivi·e, particulièrement quand on a plusieurs pathologies, l'IA ne pourrait qu'apporter de l'espoir. En pratique... c'est un peu plus compliqué. 


## 2. Les problèmes éthiques

### Les biais oppressifs

On touche là à une des premières limites de l'IA, une limite éthique, celle des biais oppressifs. Rappelons que la médecine n'est pas neutre aujourd'hui. Les soignant·es ne sont absolument pas formé·es à déconstruire leurs biais oppressifs (racistes, sexistes, lgbtqia+phobes, validistes, grossophobes, etc...), et donc la médecine est très maltraitante pour toutes les personnes appartenant à des groupes marginalisés. Et ça n'est pas uniquement la pratique de la médecine, la relation soignant·e/patient·e, qui est biaisée et oppressive, mais bien la médecine en elle-même. La médecine, en tant que science, est une science oppressive. Qui traite correctement les personnes appartenant au groupe dominant, ce qu'on considère comme le "neutre" (les hommes cis-het blancs valides globalement) et maltraite les autres. 

L'IA s'appuie sur les données existantes. Et va appuyer ses process et ses analyses sur ces données, qu'elles soient biaisées consciemment ou non. En médecine, ça veut dire que, de nouveau, les personnes appartenant à des groupes minorisés ne seront pas mieux soignées qu'elles ne le sont aujourd'hui. Voire pire, parce que les expériences montrent que l'IA va avoir tendance à développer encore plus de biais et créer des règles à partir de ces biais, il y a de grandes chances pour que toutes ces personnes soient encore moins bien soignées.

Il y a un exemple qui est souvent cité pour illustrer cette façon qu'a l'IA de prendre les biais existants et d'en faire des règles encore plus biaisées que je trouve très parlant, celui de l'IA qui avait été créée par Amazon pour son recrutement. Au milieu des années 2010, Amazon a réalisé qu'il y avait un problème : l'entreprise ne recrutait pas assez de femmes. Du coup, iels ont eu la bonne idée de créer un outil qui utiliserait l'IA pour faire une pré-sélection des cv avant entretien, l'idée étant que les humains qui faisaient cette sélection étaient biaisés (bonne analyse) et que donc l'IA apporterait un regard neutre sur la question (mauvaise conclusion). 

Bien sûr, vous vous en doutez (vu comment j'amène le sujet), ça a été une catastrophe. L'IA a sélectionné encore moins de femmes que les humains le faisaient. Et a créé tout un set de règles complètement discriminantes comme : si dans les hobbies y a un terme qualifiant de féminin (comme par exemple "capitaine de l'équipe de foot féminin") alors on ne sélectionne pas le cv, si la personne a étudié dans une école réservée aux femmes (comme il y en aux USA) alors on ne sélectionne pas le cv, et globalement l'IA donnait des notes aux cv féminins moins élevés qu'aux cv masculins. Personne n'avait donné ces règles à l'IA, mais comme elle s'était nourrie de l'historique du recrutement d'Amazon, c'était ce qu'elle en avait déduit [^4].


### La désinformation

Et bien sûr, si les biais oppressifs sont un vrai problème, un autre problème est la désinformation/mésinformation. Les IA sont de plus en plus utilisées pour chercher des informations, que ce soit directement en posant des questions à ChatGPT par exemple, ou à travers nos moteurs de recherches qui ont incorporé de l'IA dans leurs algorithmes. Sauf que l'IA dit régulièrement absolument n'importe quoi. Parfois c'est comique, comme quand des gens demandent à ChatGPT de créer une bio sur elleux-mêmes à partir de ce que l'IA trouve sur internet, et que la bio est complètement absurde... Parfois c'est très grave. 

L'un des problèmes est que l'IA est marketée comme étant toute puissante et omnisciente et que donc les gens qui l'utilisent pensent qu'ils auront forcément des résultats plus efficaces avec l'IA qu'en allant chercher la réponse à leur question sur Wikipédia [^5] par exemple. Dès l'arrivée de chatGPT, les gens ont commencé à l'utiliser comme une sorte d'assistant qui répond à toutes leurs questions et/ou carrément comme ghostwriter pour des articles sur des sujets que les personnes ne maîtrisaient pas. Sauf qu'en fait, l'IA n'est pas assez solide pour être utilisée de cette façon sans ensuite faire un gros travail de recherche de sources (et donc y passer autant de temps qu'en ayant fait la recherche soi-même).

Rappelons par exemple que tout le monde a trouvé très drôle que l'IA recommande de mettre de la glue dans ses pâtes... C'est drôle parce que c'est une erreur (hallucination est le terme qu'on est sensés utiliser) qui est vite repérable. Mais le problème c'est que toutes les hallucinations de l'IA ne sont pas aussi visibles et qu'elle passe son temps à donner des informations qui sont fausses.

Il faut dire que l'IA ne sait pas vérifier ses sources. Si vous lui posez des questions sur le vaccin contre le covid, par exemple, elle ira chercher et dans les sources scientifiques, et dans les sources antivax, et dans tous les posts d'avis de personnes lambdas qui n'y connaissent rien. Et du coup il y a de grandes chances pour qu'elle dise n'importe quoi en réponse à votre question. 

Mais il n'y a pas que le fait d'halluciner (quand elle dit n'importe quoi pour remplir un vide dans ce qu'elle trouve) ou de faire une réponse à partir de sources qui ne sont pas correctes, l'IA n'est pas capable d'interpréter les informations. Et pour répondre à une question, même simple, c'est souvent ce qu'on doit faire. Du coup, elle répond souvent à côté de la plaque et ça peut être dangereux [^6]. 


### La consommation d'énergie/pollution

Et finalement un des gros problèmes de l'IA c'est la pollution que son utilisation entraîne. Pour générer un petit texte, on se retrouve à dépenser une énergie folle... Aucun problème bien sûr puisqu'on n'est pas du tout dans un monde en pleine crise climatique avec problème de ressources énergétiques... Ah. Euh. On me dit dans l'oreillette que...

C'était la même chose avec les NFT et les cryptocurrencies, deux marottes précédentes des tech bros, et c'était déjà une critique qui semblait n'avoir aucun poids dans les discussions. Quelque part, ça devrait être la critique la plus importante, parce qu'elle est tangible : les IA utilisent bien trop de ressources pour le peu qu'elles font et dans le monde de 2024, ça n'est pas acceptable. On nous dit de pisser sous la douche pour économiser une chasse d'eau mais par contre Jean-Michel-TechBro pousse une technologie ultra polluante pour générer des textes nuls qui auraient pu être écrits plus vite et mieux par des personnes dont c'est le métier. 

C'est particulièrement choquant parce que d'un côté on a les tech bros qui poussent l'IA et de l'autre on a les tech bros qui poussent l'éco-conception (souvent avec des principes absolument pas prouvés d'ailleurs). Bon en fait c'est pas si choquant si on se rappelle que le but ultime des tech bros c'est de se faire le plus d'argent possible sur le dos de produits et concepts qui en général ne sont ni faits ni à faire. [^7]

Et comme c'est très polluant, on pourrait imaginer que du coup on décide que l'IA doit être utilisée avec parcimonie, uniquement dans les projets qui ont du sens (comme la médecine par exemple, ou l'accessibilité)... Mais non ! Au contraire, on en met absolument partout. Du coup, on a des produits qui sont que très marginalement améliorés mais qui se retrouvent à devenir ultra polluants sans raison. Tout ça parce qu'absolument toutes les entreprises veulent pouvoir dire que leur produit utilise l'IA, même quand ça n'a aucune valeur ajoutée. 



## 3. Non, je n'utilise pas l'IA (générative)

Il y a donc des utilisations de l'IA que je trouve utiles (l'accessibilité) ou qui me semblent être des pistes d'exploration intéressantes sous certaines conditions (la médecine, avec une forte réflexion sur l'éthique et une mise en place de garde-fous rigoureux). Et il y a sûrement des aspects de ma vie qui seraient complexifiées si l'IA était un domaine complètement abandonné (par exemple je me retrouverais à faire mes transcripts de [mon nouveau podcast](https://shows.acast.com/burn-your-idols) totalement manuellement et n'aurai pas forcément le temps de faire autant d'épisodes par saison [^8]). Et même dans les utilisations qui pour le moment me semblent très problématiques, comme le recrutement par exemple, je considère qu'on pourrait sûrement améliorer les outils (particulièrement en utilisant des sets de données qui soient le moins biaisés possible et en mettant des sécurités et des choses en place pour combattre les biais oppressifs), et donc que ça pourrait être utile dans le futur. Et si je pense qu'on n'a pas besoin de surutiliser l'IA pour tout et n'importe quoi, de fait il y a des tâches monotones qu'on pourrait automatiser...

Par contre, s'il y a une chose sur laquelle je ne changerai pas d'avis, c'est que je serai toujours contre l'utilisation des IA génératives (qui créent des textes, des images...). Et j'ai tellement de raisons pour être contre que j'ai été obligée de choisir celles qui me semblaient les plus importantes de peur de vous noyer dans une liste sans fin alors que mon article est déjà beaucoup trop long.[9]

Pour commencer, je dirais que mon premier problème est un problème objectif : la qualité. Que ce soient les textes ou les images, je vous mets au défi d'en générer avec une IA sans que ça se voie. Les textes sont mal écrits, les images ont des défauts que n'importe quel·le artiste apprend à éviter dans ses premières années d'apprentissage... L'outil n'est clairement pas au niveau des promesses qu'on nous fait. D'ailleurs, la plupart des gens que je connais qui utilisent l'IA pour rédiger des textes passent un certain moment à repasser dessus, même quand il s'agit de générer un court paragraphe. Donc je ne vois pas l'intérêt, si je dois passer autant de temps à éditer un texte fait par IA qu'à l'écrire de 0 c'est qu'il y a un souci de qualité de l'outil [^10].

Si pour les textes il y a possibilité de retravailler, ça n'est pas vraiment le cas des images... Et là pour moi c'est le pire de ce qui existe en terme de qualité. Je repère en général les images générées par IA en un clin d'œil, parce que ça me fait un effet de la [vallée de l'étrange](https://fr.wikipedia.org/wiki/Vall%C3%A9e_de_l%27%C3%A9trange) et me donne en général la nausée, même quand je ne vois pas de défaut consciemment sur l'image. J'imagine que c'est une question de perspectives qui sont pas correctes, peut-être d'un peu trop de symétrie ? Là encore, je sais que plein de gens n'ont pas cette réaction aux créations par IA et je connais même des gens qui trouvent certaines de ces "œuvres" jolies. Je pense que ça dépend beaucoup de si l’œil de la personne est entraîné ou non. J'ai passé mon enfance dans les musées et ma mère est artiste, j'ai aucun talent mais je pense que j'ai assez baigné dans les œuvres d'art pour être répulsée par des imitations approximatives. 

Ah et justement, je viens d'une famille d'artistes... Donc le pillage des œuvres est quelque chose que je ne peux pas considérer comme acceptable. Et non, utiliser un outil IA de génération d'images c'est pas comme s'inspirer d'une œuvre existante, ça n'a rien à voir. C'est littéralement utiliser des œuvres d'artistes sans les payer pour créer une œuvre sans aucun effort qui sera ensuite utilisée à la place d'un travail rémunéré. C'est du vol. Du pillage d'art. Et c'est s'attaquer à une classe sociale (les artistes) qui est déjà très majoritairement précaire. 

Je déteste les débats qu'il y a sur ce sujet. Les gens trouvent normal qu'on vole le travail d'artistes pour que des programmes informatiques créent des œuvres à la place des artistes. Donc on vole deux fois les artistes, dans un premier temps en utilisant leurs œuvres sans autorisation, une deuxième fois en les remplaçant par un ersatz d’œuvres volées. Et c'est hyper compliqué de faire comprendre aux gens qui ne font pas de travail artistiques pourquoi c'est problématique. Ils font des parallèles avec les inspirations (une machine ne peut pas être inspirée, il n'y a pas de création), et disent des choses du genre "à chaque fois que des métiers sont automatisés on a crié à la fin du monde et en fait c'était juste du progressisme". 

Alors.

En fait, non.

Parce que oui, automatiser des tâches répétitives, sans intérêts et qui, souvent, créaient des maladies professionnelles, c'est positif. Oui bien sûr il y a un changement sociétal lié au fait d'automatiser les usines, mais globalement si les choses étaient bien faites (et qu'on n'essayait pas juste d'en tirer le plus de profit), logiquement ça devrait améliorer la vie des ouvrières et ouvriers à tous les niveaux.

Par contre, si vous automatisez la création artistique, vous améliorez la vie de qui, exactement ? Outre le fait que l'IA ne crée pas, et que donc on se retrouve avec des "œuvres" moches, répétitives et qu'on abandonne tout sous-texte et toute volonté artistique derrière ces "œuvres", la question reste : que deviennent les artistes ? 

L'être humain a toujours fait de l'art. La création est vitale à notre espèce, que ce soit au niveau de nos sociétés, qu'au niveau des individus. Certain·es d'entre nous créent et reçoivent l'art, d'autres reçoivent uniquement, mais quoi qu'il en soit tout le monde a besoin de l'art, de la fiction, de la créativité. Si on laisse tout ça à l'IA, qu'est-ce qui nous reste ? Et de quoi on va se nourrir ? 

L'art a toujours poussé à la réflexion, a toujours aidé à comprendre ses sentiments, voire a pu être thérapeutique. Vu ce que l'IA génère pour le moment, on est très loin d'atteindre même uniquement un de ces trois objectifs. 

Moi ce que je veux c'est que l'IA automatise les tâches inintéressantes que j'ai à faire (mon ménage, mes transcripts) et que ça me laisse plus de temps pour la création. Pour écrire, mais aussi pour explorer d'autres médias que je n'ai pas le temps ou l'énergie d'explorer aujourd'hui. En vrai, je veux même avoir plus de temps pour regarder des séries, écouter de la musique, lire des livres... Bref, "consommer" de l'art. 

L'utopie qu'on pensait avoir c'était d'avoir des robots qui faisaient toutes nos tâches monotones et qu'on pourrait passer plus de temps à être créatif·ves et à réfléchir... Mais les tech bros sont en train de créer un avenir où l'IA se charge de l'art et on se retrouve à ne plus faire que les tâches monotones... Autant vous dire que ça n'est pas le futur dont je rêve. 


> __Quelques ressources sur les problématiques liées aux biais oppressifs dans l'IA [^11] :__
>> [Demain, les IA seront-elles transphobes (et fières de l’être) ?  par Blanche Ribault](https://usbeketrica.com/fr/article/demain-les-ia-seront-elles-transphobes-et-fieres-de-l-etre)
>> [Yes, AI Is Screwing Over Black Folks, But Here's How We Can Game The System par Cali Green - en anglais](https://www.theroot.com/ai-is-a-problem-for-black-folks-heres-how-we-can-make-1851555455)
> __Quelques ressources sur les problématiques liées aux informations dans l'IA :__
>> [ChatGPT et l’indifférence à la vérité par Arthur Perret](https://www.arthurperret.fr/blog/2024-06-21-chatgpt-et-l-indifference-a-la-verite.html)
>> [Grok est un superdiffuseur de désinformation  par Mathilde Saliou](https://next.ink/147023/grok-est-un-superdiffuseur-de-desinformation/)
>> [The types information available on the internet and why AI is bad for all of them par Nic - en anglais](https://www.nicchan.me/blog/the-types-of-information-available-on-the-internet-and-why-ai-is-bad-for-all-of-them/)
> Quelques ressources en vrac sur le sujet :
>> [Intelligence artificielle et santé - dossier de l'Inserm](https://www.inserm.fr/dossier/intelligence-artificielle-et-sante/)
>> [Intelligence artificielle, anxiété réelle : pourquoi nous sommes terrifiés, et totalement fans, de l'IA par Eilleen Yu](https://www.zdnet.fr/actualites/intelligence-artificielle-anxiete-reelle-pourquoi-nous-sommes-terrifies-et-totalement-fans-de-lia-395892.htm)
>> [Le futur n'existe pas par Thibault Prévost](https://www-arretsurimages-net.bnf.idm.oclc.org/chroniques/clic-gauche/le-futur-nexiste-pas)
>> [Exclusive: OpenAI Used Kenyan Workers on Less Than $2 Per Hour to Make ChatGPT Less Toxic par Billy Perrigo - en anglais](https://time.com/6247678/openai-chatgpt-kenya-workers/)



[1] Les luddites étaient des travailleurs d'usines textiles, puis dans l'agriculture qui s'opposaient à l'automatisation et donc à l'utilisation de certaines machines. Aujourd'hui, ce terme est plus ou moins repris par un courant idéologique qui prône le fait d'utiliser le moins d'outils informatique possible, allant de personnes qui refusent même d'utiliser des ordinateurs, à juste des personnes qui limitent leurs utilisations de ces outils au strict minimum. 

[2] Bon du coup, ça supprime aussi les emplois générés par cette tâche... dans un monde parfait ça voudrait dire que les gens peuvent avoir des activités plus épanouissantes mais dans un monde comme le nôtre, ça veut juste dire plus de chômage. 

[3] Le NaNoWriMo, un évènement très populaire centré autour de l'écriture, vient de justifier le fait d'encourager les gens à utiliser de l'IA pour écrire, par le fait que c'était utile pour les personnes neuro-atypiques... Ce qui n'a aucun sens et est en fait validiste, les personnes neuroA n'ayant pas plus besoin qu'un ordinateur leur crée leur texte pour raconter une histoire que n'importe qui d'autre. 

[4] Du coup, l'IA serait peut-être un outil intéressant pour déceler les biais dans un système plus que pour les outrepasser. 

[5] Y a plein de critiques à faire sur wikipédia, et c'est clairement pas une source suffisante si on veut aller au coeur d'un sujet, mais globalement on n'y trouve pas en général des informations complètement fausses. 

[6] Et d'un coup entre la question des biais oppressifs et la question de l'incapacité à séparer une vraie information d'une fausse, mon enthousiasme pour l'utilisation en médecine a complètement disparu et celui pour l'accessibilité s'est pas mal refroidi.

[7] Et oui, je suis persuadée que comme les cryptocurrencies et les NFT, l'IA est une bulle et qu'elle commence déjà à éclater... Le problème c'est que comme ils en mettent dans tous nos outils, ça va pas être drôle quand ça n'intéressera plus personne et qu'on sera abandonné·es avec des outils qui fonctionnent moins bien qu'avant. 

[8] On me reproche souvent de ne pas savoir faire mon auto-promo, est-ce que ça fonctionne comme ça ? 

[9] D'ailleurs je suis loin d'avoir évoqué tous les problèmes liés à l'IA. Dans les problèmes assez terrifiants que je n'ai pas évoqués il y a : la création de chatbots faits pour remplacer les humains dans des situations de soutien psychologique, la création de contenus pédagogiques par IA (une calamité), l'utilisation de l'IA dans la sécurité pour juger des intentions d'une personnes via ses attitudes physiques (le retour de la phrénologie), ou la question de l'exploitation des travailleureuses qui entretiennent ces modèles...

[10] Je suis consciente du fait que tout le monde n'a pas passé sa vie à écrire et n'écrit pas forcément rapidement. J'ai discuté plusieurs fois avec des gens qui utilisent le texte généré par IA comme appui pour ensuite écrire leur texte parce qu'écrire une structure de texte leur prend des plombes et que ça leur évite toute une partie du travail. Honnêtement, je suis mitigée vis-à-vis de cette utilisation dans l'absolu mais j'ai conscience que c'est sûrement un peu biaisé de ma part et que je n'ai pas une expérience de l'écriture qui est la plus commune donc j'évite d'en faire une généralité. 

[11] Merci à mon adversaire Emmanuelle qui a passé des semaines à m'envoyer des articles qu'elle trouvait au fur et à mesure... J'en ai utilisés pas mal en ressources à partager ici parce qu'ils étaient tous hyper intéressants et plutôt récents contrairement à mes sources qui commençaient à dater. 